{"metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3.11", "language": "python"}, "language_info": {"name": "python", "version": "3.11.9", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}}, "nbformat_minor": 4, "nbformat": 4, "cells": [{"cell_type": "code", "source": "pip install spacy", "metadata": {"id": "14b119f9-d898-472a-a8d6-d00329b0e63f"}, "outputs": [{"name": "stdout", "text": "Collecting spacy\n  Downloading spacy-3.8.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (27 kB)\nCollecting spacy-legacy<3.1.0,>=3.0.11 (from spacy)\n  Downloading spacy_legacy-3.0.12-py2.py3-none-any.whl.metadata (2.8 kB)\nCollecting spacy-loggers<2.0.0,>=1.0.0 (from spacy)\n  Downloading spacy_loggers-1.0.5-py3-none-any.whl.metadata (23 kB)\nCollecting murmurhash<1.1.0,>=0.28.0 (from spacy)\n  Downloading murmurhash-1.0.12-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.1 kB)\nCollecting cymem<2.1.0,>=2.0.2 (from spacy)\n  Downloading cymem-2.0.11-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.5 kB)\nCollecting preshed<3.1.0,>=3.0.2 (from spacy)\n  Downloading preshed-3.0.9-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.2 kB)\nCollecting thinc<8.4.0,>=8.3.4 (from spacy)\n  Downloading thinc-8.3.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (15 kB)\nCollecting wasabi<1.2.0,>=0.9.1 (from spacy)\n  Downloading wasabi-1.1.3-py3-none-any.whl.metadata (28 kB)\nCollecting srsly<3.0.0,>=2.4.3 (from spacy)\n  Downloading srsly-2.5.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (19 kB)\nCollecting catalogue<2.1.0,>=2.0.6 (from spacy)\n  Downloading catalogue-2.0.10-py3-none-any.whl.metadata (14 kB)\nCollecting weasel<0.5.0,>=0.1.0 (from spacy)\n  Downloading weasel-0.4.1-py3-none-any.whl.metadata (4.6 kB)\nRequirement already satisfied: typer<1.0.0,>=0.3.0 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from spacy) (0.12.3)\nRequirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from spacy) (4.66.4)\nRequirement already satisfied: numpy>=1.19.0 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from spacy) (1.26.4)\nRequirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from spacy) (2.32.2)\nRequirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from spacy) (2.8.2)\nRequirement already satisfied: jinja2 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from spacy) (3.1.5)\nRequirement already satisfied: setuptools in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from spacy) (72.1.0)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from spacy) (23.2)\nCollecting langcodes<4.0.0,>=3.2.0 (from spacy)\n  Downloading langcodes-3.5.0-py3-none-any.whl.metadata (29 kB)\nCollecting language-data>=1.2 (from langcodes<4.0.0,>=3.2.0->spacy)\n  Downloading language_data-1.3.0-py3-none-any.whl.metadata (4.3 kB)\nRequirement already satisfied: annotated-types>=0.4.0 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.6.0)\nRequirement already satisfied: pydantic-core==2.20.1 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.20.1)\nRequirement already satisfied: typing-extensions>=4.6.1 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.11.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.4)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.19)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2025.1.31)\nCollecting blis<1.3.0,>=1.2.0 (from thinc<8.4.0,>=8.3.4->spacy)\n  Downloading blis-1.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\nCollecting confection<1.0.0,>=0.0.1 (from thinc<8.4.0,>=8.3.4->spacy)\n  Downloading confection-0.1.5-py3-none-any.whl.metadata (19 kB)\nRequirement already satisfied: click>=8.0.0 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.7)\nRequirement already satisfied: shellingham>=1.3.0 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\nRequirement already satisfied: rich>=10.11.0 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from typer<1.0.0,>=0.3.0->spacy) (13.7.1)\nCollecting cloudpathlib<1.0.0,>=0.7.0 (from weasel<0.5.0,>=0.1.0->spacy)\n  Downloading cloudpathlib-0.20.0-py3-none-any.whl.metadata (14 kB)\nRequirement already satisfied: smart-open<8.0.0,>=5.2.1 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.0.4)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from jinja2->spacy) (2.1.3)\nCollecting marisa-trie>=1.1.0 (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy)\n  Downloading marisa_trie-1.2.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.0 kB)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.15.1)\nRequirement already satisfied: wrapt in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.14.1)\nRequirement already satisfied: mdurl~=0.1 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\nDownloading spacy-3.8.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30.6 MB)\n\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m30.6/30.6 MB\u001b[0m \u001b[31m145.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading catalogue-2.0.10-py3-none-any.whl (17 kB)\nDownloading cymem-2.0.11-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (218 kB)\n\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m218.9/218.9 kB\u001b[0m \u001b[31m108.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading langcodes-3.5.0-py3-none-any.whl (182 kB)\n\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m183.0/183.0 kB\u001b[0m \u001b[31m102.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading murmurhash-1.0.12-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (134 kB)\n\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m134.3/134.3 kB\u001b[0m \u001b[31m87.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading preshed-3.0.9-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (157 kB)\n\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m157.2/157.2 kB\u001b[0m \u001b[31m94.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading spacy_legacy-3.0.12-py2.py3-none-any.whl (29 kB)\nDownloading spacy_loggers-1.0.5-py3-none-any.whl (22 kB)\nDownloading srsly-2.5.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m190.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading thinc-8.3.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.9 MB)\n\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m3.9/3.9 MB\u001b[0m \u001b[31m198.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading wasabi-1.1.3-py3-none-any.whl (27 kB)\nDownloading weasel-0.4.1-py3-none-any.whl (50 kB)\n\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m50.3/50.3 kB\u001b[0m \u001b[31m37.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading blis-1.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.7 MB)\n\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m11.7/11.7 MB\u001b[0m \u001b[31m189.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading cloudpathlib-0.20.0-py3-none-any.whl (52 kB)\n\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m52.5/52.5 kB\u001b[0m \u001b[31m33.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading confection-0.1.5-py3-none-any.whl (35 kB)\nDownloading language_data-1.3.0-py3-none-any.whl (5.4 MB)\n\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m208.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading marisa_trie-1.2.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.4 MB)\n\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m176.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: cymem, wasabi, spacy-loggers, spacy-legacy, murmurhash, marisa-trie, cloudpathlib, catalogue, blis, srsly, preshed, language-data, langcodes, confection, weasel, thinc, spacy\nSuccessfully installed blis-1.2.0 catalogue-2.0.10 cloudpathlib-0.20.0 confection-0.1.5 cymem-2.0.11 langcodes-3.5.0 language-data-1.3.0 marisa-trie-1.2.1 murmurhash-1.0.12 preshed-3.0.9 spacy-3.8.4 spacy-legacy-3.0.12 spacy-loggers-1.0.5 srsly-2.5.1 thinc-8.3.4 wasabi-1.1.3 weasel-0.4.1\nNote: you may need to restart the kernel to use updated packages.\n", "output_type": "stream"}], "execution_count": 2}, {"cell_type": "code", "source": "import spacy\nfrom spacy.cli import download\n\n# Download the model programmatically\ndownload(\"en_core_web_sm\")\nnlp = spacy.load(\"en_core_web_sm\")\n", "metadata": {"id": "16274beb-f35e-43b2-9544-d7b9c2ef7bc5"}, "outputs": [{"name": "stdout", "text": "Collecting en-core-web-sm==3.8.0\n  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m168.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: en-core-web-sm\nSuccessfully installed en-core-web-sm-3.8.0\n\u001b[38;5;2m\u2714 Download and installation successful\u001b[0m\nYou can now load the package via spacy.load('en_core_web_sm')\n\u001b[38;5;3m\u26a0 Restart to reload dependencies\u001b[0m\nIf you are in a Jupyter or Colab notebook, you may need to restart Python in\norder to load all the package's dependencies. You can do this by selecting the\n'Restart kernel' or 'Restart runtime' option.\n", "output_type": "stream"}], "execution_count": 6}, {"cell_type": "code", "source": "pip install nltk", "metadata": {"id": "8bede0c6-05ab-4c92-bc02-eb46fddb7145"}, "outputs": [{"name": "stdout", "text": "Requirement already satisfied: nltk in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (3.9.1)\nRequirement already satisfied: click in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from nltk) (8.1.7)\nRequirement already satisfied: joblib in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from nltk) (1.3.2)\nRequirement already satisfied: regex>=2021.8.3 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from nltk) (2023.10.3)\nRequirement already satisfied: tqdm in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from nltk) (4.66.4)\nNote: you may need to restart the kernel to use updated packages.\n", "output_type": "stream"}], "execution_count": 10}, {"cell_type": "code", "source": "import nltk\nnltk.download('punkt_tab')\n", "metadata": {"id": "5145555a-a9e3-4ddb-bf2f-982d3bd2dfbe"}, "outputs": [{"name": "stderr", "text": "[nltk_data] Downloading package punkt_tab to /home/wsuser/nltk_data...\n[nltk_data]   Package punkt_tab is already up-to-date!\n", "output_type": "stream"}, {"execution_count": 11, "output_type": "execute_result", "data": {"text/plain": "True"}, "metadata": {}}], "execution_count": 11}, {"cell_type": "code", "source": "import re\nimport spacy\nimport pandas as pd\nfrom nltk.corpus import stopwords\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\n# Load SpaCy model for advanced NLP\nnlp = spacy.load(\"en_core_web_sm\")\n\n# Sample text data\ntext_data = [\n    \"Improving text analytics data quality with advanced NLP techniques.\",\n    \"This is a sample text for demonstrating NLP preprocessing.\",\n    \"Text analytics can be improved using machine learning and NLP.\"\n]\n\n# Text Cleaning Function\ndef clean_text(text):\n    # Remove special characters and numbers\n    text = re.sub(r'\\W', ' ', text)  # Remove non-word characters\n    text = re.sub(r'\\d+', '', text)  # Remove digits\n    text = text.lower()  # Convert to lowercase\n    text = re.sub(r'\\s+', ' ', text)  # Replace multiple spaces with a single space\n    text = text.strip()  # Remove leading/trailing whitespace\n    return text\n\n# Tokenization and Lemmatization Function (with SpaCy for efficiency)\ndef preprocess_text(text):\n    doc = nlp(text)\n    # Remove stopwords and lemmatize\n    tokens = [token.lemma_ for token in doc if not token.is_stop and not token.is_punct]\n    return ' '.join(tokens)\n\n# Advanced NLP Processing with SpaCy (Entity, Noun, Verb extraction)\ndef advanced_nlp_processing(text):\n    doc = nlp(text)\n    # Extract named entities, nouns, and verbs\n    entities = [ent.text for ent in doc.ents]\n    nouns = [token.text for token in doc if token.pos_ == \"NOUN\"]\n    verbs = [token.text for token in doc if token.pos_ == \"VERB\"]\n    return entities, nouns, verbs\n\n# Apply cleaning and preprocessing to text data\ncleaned_texts = [clean_text(text) for text in text_data]\npreprocessed_texts = [preprocess_text(text) for text in cleaned_texts]\n\n# Apply advanced NLP processing\nadvanced_results = [advanced_nlp_processing(text) for text in preprocessed_texts]\n\n# TF-IDF Vectorization for feature extraction (with optimized stopword removal)\ntfidf_vectorizer = TfidfVectorizer(max_features=10, stop_words='english')\ntfidf_matrix = tfidf_vectorizer.fit_transform(preprocessed_texts)\n\n# Convert TF-IDF matrix to DataFrame for better visualization\ntfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=tfidf_vectorizer.get_feature_names_out())\n\n# Output results\nprint(\"Cleaned Texts:\\n\", cleaned_texts)\nprint(\"\\nPreprocessed Texts:\\n\", preprocessed_texts)\nprint(\"\\nAdvanced NLP Results:\\n\", advanced_results)\nprint(\"\\nTF-IDF Matrix:\\n\", tfidf_df)\n\n# Save results to a CSV file (optional)\ntfidf_df.to_csv(\"tfidf_results.csv\", index=False)\n", "metadata": {"id": "436ff9c8-7cde-4f7c-836e-4915b72091bd"}, "outputs": [{"name": "stdout", "text": "Cleaned Texts:\n ['improving text analytics data quality with advanced nlp techniques', 'this is a sample text for demonstrating nlp preprocessing', 'text analytics can be improved using machine learning and nlp']\n\nPreprocessed Texts:\n ['improve text analytic datum quality advanced nlp technique', 'sample text demonstrate nlp preprocessing', 'text analytic improve machine learning nlp']\n\nAdvanced NLP Results:\n [([], ['text', 'datum', 'quality', 'nlp', 'technique'], ['improve']), ([], ['sample', 'text', 'nlp', 'preprocessing'], ['demonstrate']), ([], ['text', 'machine', 'nlp'], ['improve', 'learning'])]\n\nTF-IDF Matrix:\n    advanced  analytic     datum  demonstrate   improve  learning   machine  \\\n0  0.509353  0.387376  0.509353     0.000000  0.387376  0.000000  0.000000   \n1  0.000000  0.000000  0.000000     0.608845  0.000000  0.000000  0.000000   \n2  0.000000  0.387376  0.000000     0.000000  0.387376  0.509353  0.509353   \n\n        nlp  preprocessing      text  \n0  0.300832       0.000000  0.300832  \n1  0.359594       0.608845  0.359594  \n2  0.300832       0.000000  0.300832  \n", "output_type": "stream"}], "execution_count": 12}, {"cell_type": "code", "source": "", "metadata": {"id": "0d3aa58a-8546-41ab-94be-86d28a6cc70a"}, "outputs": [], "execution_count": null}]}